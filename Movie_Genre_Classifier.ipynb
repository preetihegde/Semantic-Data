{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZnMRt3f3MnHs",
        "outputId": "a1385899-3d76-4fd9-e2fe-af2de74bc8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hQlpaY5Ifnso",
        "outputId": "7820eee2-e9c6-4332-8a98-6746bb1e00ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define column names for your DataFrame\n",
        "head_column = ['serial_number','movie_title', 'genre', 'movie_description']\n",
        "\n",
        "df = pd.read_csv(r'./drive/MyDrive/Colab Notebooks/train_data.txt', sep=':::', names= head_column, engine='python')\n",
        "\n",
        "df['year'] = df['movie_title'].str.extract(r'\\((\\d{4})\\)', expand=False)\n",
        "df['movie_title'] = df['movie_title'].str.extract(r'(.+?) \\(\\d+\\)')\n",
        "\n",
        "print(df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hYrUyqjZShY7",
        "outputId": "a4b19ea4-b8b5-4997-cfa3-5e8fa268ba9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serial_number        54214\n",
            "movie_title          49867\n",
            "genre                54214\n",
            "movie_description    54214\n",
            "year                 49867\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "#Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stop_words(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "# Apply stop words removal to the 'movie_description' column\n",
        "df['movie_description'] = df['movie_description'].apply(remove_stop_words)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "yMwmTjoRUsgC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2c68f332-7734-47ee-d9f0-e86fa133735a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   serial_number                 movie_title       genre  \\\n",
            "0              1       Oscar et la dame rose      drama    \n",
            "1              2                       Cupid   thriller    \n",
            "2              3   Young, Wild and Wonderful      adult    \n",
            "3              4              The Secret Sin      drama    \n",
            "4              5             The Unrecovered      drama    \n",
            "\n",
            "                                   movie_description  year  \n",
            "0  Listening conversation doctor parents , 10-yea...  2009  \n",
            "1  brother sister past incestuous relationship cu...  1997  \n",
            "2  bus empties students field trip Museum Natural...  1980  \n",
            "3  help unemployed father make ends meet , Edith ...  1915  \n",
            "4  film 's title refers un-recovered bodies groun...  2007  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform lemmatization\n",
        "def perform_lemmatization(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply stemming and lemmatization to the 'Plot' column\n",
        "df['movie_description'] = df['movie_description'].apply(perform_lemmatization)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5uubzCOUgFYg",
        "outputId": "93f955e0-507e-4819-abd3-319490dcf149"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   serial_number                 movie_title       genre  \\\n",
            "0              1       Oscar et la dame rose      drama    \n",
            "1              2                       Cupid   thriller    \n",
            "2              3   Young, Wild and Wonderful      adult    \n",
            "3              4              The Secret Sin      drama    \n",
            "4              5             The Unrecovered      drama    \n",
            "\n",
            "                                   movie_description  year  \n",
            "0  Listening conversation doctor parent , 10-year...  2009  \n",
            "1  brother sister past incestuous relationship cu...  1997  \n",
            "2  bus empty student field trip Museum Natural Hi...  1980  \n",
            "3  help unemployed father make end meet , Edith t...  1915  \n",
            "4  film 's title refers un-recovered body ground ...  2007  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['movie_description'], df['genre'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Feature Extraction\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "tL5y1xNoh80C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training using Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_rf = rf_classifier.predict(X_test_tfidf)\n",
        "accuracy_rf = metrics.accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf= metrics.precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall_rf = metrics.recall_score(y_test, y_pred_rf, average='weighted')\n",
        "f1_rf= metrics.f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(f\"Random Forest - \\n Accuracy: {accuracy_rf:.2f}, Precision: {precision_rf:.2f}, Recall: {recall_rf:.2f}, F1 Score: {f1_rf:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQE97Joe1Ycg",
        "outputId": "acf8d7b9-86b5-446e-d5b1-fadc45c93f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - \n",
            " Accuracy: 0.50, Precision: 0.50, Recall: 0.50, F1 Score: 0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training using Multinomial naive bayes\n",
        "mnb_classifier = MultinomialNB()\n",
        "mnb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "mnb_pred = mnb_classifier.predict(X_test_tfidf)\n",
        "accuracy = metrics.accuracy_score(y_test, mnb_pred)\n",
        "precision = metrics.precision_score(y_test, mnb_pred, average='weighted')\n",
        "recall = metrics.recall_score(y_test, mnb_pred, average='weighted')\n",
        "f1 = metrics.f1_score(y_test, mnb_pred, average='weighted')\n",
        "\n",
        "print(f\"MultiNomialNB - \\n Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-xahJ9u0TQ_",
        "outputId": "594c442e-a161-487f-e2d7-58ced825bf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiNomialNB - \n",
            " Accuracy: 0.52, Precision: 0.49, Recall: 0.52, F1 Score: 0.43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training using support vector machines\n",
        "svm_classifier = SVC(kernel='sigmoid')\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_svm = svm_classifier.predict(X_test_tfidf)\n",
        "accuracy_svm = metrics.accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = metrics.precision_score(y_test, y_pred_svm, average='weighted')\n",
        "recall_svm = metrics.recall_score(y_test, y_pred_svm, average='weighted')\n",
        "f1_svm = metrics.f1_score(y_test, y_pred_svm, average='weighted')\n",
        "\n",
        "print(f\"SVM - \\n Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1 Score: {f1_svm:.2f}\")\n"
      ],
      "metadata": {
        "id": "J5gYiO100tLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5f6778-2584-401d-ad1d-39ec2f8b1fa3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM - \n",
            " Accuracy: 0.58, Precision: 0.55, Recall: 0.58, F1 Score: 0.55\n"
          ]
        }
      ]
    }
  ]
}