### Presentations 

This folder consists of 2 different Presentations on topics : 

***An Attention Model Based on Spatial Transformers for Scence Recognition*** 

In this paper, an Attention Model Based on Spatial Transformers is proposed for Scene Recognition, aiming to empower computers with the ability to automatically identify and understand different scenes in images. Combining Convolutional Neural Networks (CNNs) with this attention model, the system learns to recognize important regions in an image, leveraging a Spatial Transformer Network that adapts to scales and movements. This approach allows the model to discern key areas in a data-driven manner without requiring additional guidance. The experiments conducted on a subset of the Places205 database demonstrate the effectiveness of the proposed model, achieving a top-1 accuracy of 82.10% and outperforming comparable models like PlacesCNN. This research contributes to advancing computer vision capabilities for more accurate and autonomous scene recognition.

>[!Info]
>[An Attention Model Based on Spatial Transformers for Scence Recognition](https://ieeexplore.ieee.org/abstract/document/7900219?casa_token=P3PCai3MSl8AAAAA:Wsx0DYvC_LFzxJ5FzV65WoPKevFgCJnHQeoAgH6h0GlF27xYFd_I72MvnvnhWycoYPvxUqwKRvwS)

***Hyperbolic Word Embeddings***
            
In this paper, the authors propose a novel method for unsupervised word embeddings, embedding words in a Cartesian product of hyperbolic spaces. They connect this concept to Gaussian word embeddings and Fisher geometry, adapting the Glove algorithm for training on Riemannian manifolds. The introduced embeddings outperform strong baselines in similarity, analogy, and hypernymy detection tasks. Notably, the embeddings achieve a new state-of-the-art fully unsupervised WBLESS classification accuracy for the word hypernymy.

>[!Note]
>[Hyperbolic Word Embeddings](https://arxiv.org/abs/1810.06546)
 
